from openai import OpenAI

# Initialize the OpenAI client with your API key
client = OpenAI(api_key="OPENAI_API_KEY")


completion = client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Meu nome é Daniel."},
    {"role": "user", "content": "Qual meu nome?"}
  ]
)
print(completion.choices[0].message.content)
'''

# function that takes in string argument as parameter
def chat(MSGS, MaxToken=50, outputs=3):
    # We use the Chat Completion endpoint for chat like inputs
    response = client.chat.completions.create(
    # model used here is ChatGPT
    # You can use all these models for this endpoint: 
    # gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314, 
    # gpt-3.5-turbo, gpt-3.5-turbo-0301
    model="gpt-4o-mini",
    messages=MSGS,
    # max_tokens generated by the AI model
    # maximu value can be 4096 tokens for "gpt-3.5-turbo" 
    max_tokens = MaxToken,
    # number of output variations to be generated by AI model
    n = outputs,
    )
    return response.choices[0].message

# Messages must consist of a collection of message objects, 
# each of which includes a role (either "system," "user," or "assistant") 
# and a content field for the message's actual text. 
# Conversations might last only 1 message or span several pages.
MSGS = [
        {"role": "system", "content": "<message generated by system>"},
        {"role": "user", "content": "<message generated by user>"},
        {"role": "assistant", "content": "<message generated by assistant>"}
    ]


prompt = [{"role": "user", "content": "Meu nome é Alex."}]
print(chat(prompt, MaxToken=500, outputs=1).content)
prompt2 = [{"role": "user", "content": "Qual é meu nome?"}]
print(chat(prompt2, MaxToken=500, outputs=1).content)
#print(comp(prompt, MaxToken=3000, outputs=3))

'''
'''
def main():
    prompt = "Me dê um resumo do filme O senhor dos aneis."
    print(comp(PROMPT, MaxToken=3000, outputs=3))
    return 0
'''